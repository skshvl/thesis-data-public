{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe containing all SHAP maps for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LXMERT_shap_maps.pickle',\n",
       "  'CLIP_shap_maps.pickle',\n",
       "  'SigLip_shap_maps.pickle',\n",
       "  'FLAVA_shap_maps.pickle'],\n",
       " ['LXMERT', 'CLIP', 'SigLip', 'FLAVA'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "shap_map_dir = \"../xai_maps/xai_output\"\n",
    "all_files = os.listdir(shap_map_dir)\n",
    "relevant_filenames = [filename for filename in all_files if \"shap_maps.pickle\" in filename]\n",
    "model_names = [filename.split(\"_\")[0] for filename in relevant_filenames]\n",
    "relevant_filenames, model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create shared DF with model names and shap outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model_shap_map</th>\n",
       "      <th>n_image_variants</th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../VALSE_data/images/coco2017/000000411953.jpg</td>\n",
       "      <td>a guy plays guitar on the stage center</td>\n",
       "      <td>A guy plays guitar off the stage center</td>\n",
       "      <td>relations</td>\n",
       "      <td>[[0.0010528630991757382, 0.0001818203072616597...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>000000411953.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../VALSE_data/images/swig/licking_291.jpg</td>\n",
       "      <td>A cow licks its fur.</td>\n",
       "      <td>A cow wrinkles its fur.</td>\n",
       "      <td>actions</td>\n",
       "      <td>[[-0.055763863715583284, 0.022721240122336894,...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>licking_291.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../VALSE_data/images/swig/counting_103.jpg</td>\n",
       "      <td>A person counts money.</td>\n",
       "      <td>A person pays money.</td>\n",
       "      <td>actions</td>\n",
       "      <td>[[-0.0010253147265757434, 0.001289952102524694...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>counting_103.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2411632.jpg</td>\n",
       "      <td>There are no people in the photo.</td>\n",
       "      <td>There is at least one person in the photo.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[0.000928994850255549, -0.011200517765246332,...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>v7w_2411632.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../VALSE_data/images/swig/urinating_251.jpg</td>\n",
       "      <td>A man urinates against a wall.</td>\n",
       "      <td>A man skates against a wall.</td>\n",
       "      <td>actions</td>\n",
       "      <td>[[0.022377102646714775, 0.10345780447460129, -...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>urinating_251.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2363335.jpg</td>\n",
       "      <td>There is a mast on the closest boat.</td>\n",
       "      <td>There is no mast on the closest boat.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[0.05296492576599121, -0.05216550827026367, -...</td>\n",
       "      <td>172</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>v7w_2363335.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2367084.jpg</td>\n",
       "      <td>There is a giraffe.</td>\n",
       "      <td>There is no giraffe.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[0.7628903388977051, -0.021378040313720703, -...</td>\n",
       "      <td>172</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>v7w_2367084.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2373121.jpg</td>\n",
       "      <td>There are no clouds in the sky.</td>\n",
       "      <td>There is at least one cloud in the sky.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[-0.5447151064872742, -0.09526211023330688, -...</td>\n",
       "      <td>172</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>v7w_2373121.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2390850.jpg</td>\n",
       "      <td>There are no people in the water.</td>\n",
       "      <td>There is at least one person in the water.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[-0.042334675788879395, 0.08342540264129639, ...</td>\n",
       "      <td>172</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>v7w_2390850.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>../../VALSE_data/images/v7w/v7w_2416322.jpg</td>\n",
       "      <td>There is at least one person wearing glasses.</td>\n",
       "      <td>There are no people wearing glasses.</td>\n",
       "      <td>existence</td>\n",
       "      <td>[[-0.13773280382156372, 0.17260807752609253, -...</td>\n",
       "      <td>172</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>v7w_2416322.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path  \\\n",
       "0   ../../VALSE_data/images/coco2017/000000411953.jpg   \n",
       "1        ../../VALSE_data/images/swig/licking_291.jpg   \n",
       "2       ../../VALSE_data/images/swig/counting_103.jpg   \n",
       "3         ../../VALSE_data/images/v7w/v7w_2411632.jpg   \n",
       "4      ../../VALSE_data/images/swig/urinating_251.jpg   \n",
       "..                                                ...   \n",
       "94        ../../VALSE_data/images/v7w/v7w_2363335.jpg   \n",
       "95        ../../VALSE_data/images/v7w/v7w_2367084.jpg   \n",
       "96        ../../VALSE_data/images/v7w/v7w_2373121.jpg   \n",
       "97        ../../VALSE_data/images/v7w/v7w_2390850.jpg   \n",
       "98        ../../VALSE_data/images/v7w/v7w_2416322.jpg   \n",
       "\n",
       "                                          caption  \\\n",
       "0          a guy plays guitar on the stage center   \n",
       "1                            A cow licks its fur.   \n",
       "2                          A person counts money.   \n",
       "3               There are no people in the photo.   \n",
       "4                  A man urinates against a wall.   \n",
       "..                                            ...   \n",
       "94           There is a mast on the closest boat.   \n",
       "95                            There is a giraffe.   \n",
       "96                There are no clouds in the sky.   \n",
       "97              There are no people in the water.   \n",
       "98  There is at least one person wearing glasses.   \n",
       "\n",
       "                                          foil linguistic_phenomena  \\\n",
       "0      A guy plays guitar off the stage center            relations   \n",
       "1                      A cow wrinkles its fur.              actions   \n",
       "2                         A person pays money.              actions   \n",
       "3   There is at least one person in the photo.            existence   \n",
       "4                 A man skates against a wall.              actions   \n",
       "..                                         ...                  ...   \n",
       "94       There is no mast on the closest boat.            existence   \n",
       "95                        There is no giraffe.            existence   \n",
       "96     There is at least one cloud in the sky.            existence   \n",
       "97  There is at least one person in the water.            existence   \n",
       "98        There are no people wearing glasses.            existence   \n",
       "\n",
       "                                       model_shap_map  n_image_variants  \\\n",
       "0   [[0.0010528630991757382, 0.0001818203072616597...               172   \n",
       "1   [[-0.055763863715583284, 0.022721240122336894,...               172   \n",
       "2   [[-0.0010253147265757434, 0.001289952102524694...               172   \n",
       "3   [[0.000928994850255549, -0.011200517765246332,...               172   \n",
       "4   [[0.022377102646714775, 0.10345780447460129, -...               172   \n",
       "..                                                ...               ...   \n",
       "94  [[0.05296492576599121, -0.05216550827026367, -...               172   \n",
       "95  [[0.7628903388977051, -0.021378040313720703, -...               172   \n",
       "96  [[-0.5447151064872742, -0.09526211023330688, -...               172   \n",
       "97  [[-0.042334675788879395, 0.08342540264129639, ...               172   \n",
       "98  [[-0.13773280382156372, 0.17260807752609253, -...               172   \n",
       "\n",
       "     model           filename  \n",
       "0   LXMERT   000000411953.jpg  \n",
       "1   LXMERT    licking_291.jpg  \n",
       "2   LXMERT   counting_103.jpg  \n",
       "3   LXMERT    v7w_2411632.jpg  \n",
       "4   LXMERT  urinating_251.jpg  \n",
       "..     ...                ...  \n",
       "94   FLAVA    v7w_2363335.jpg  \n",
       "95   FLAVA    v7w_2367084.jpg  \n",
       "96   FLAVA    v7w_2373121.jpg  \n",
       "97   FLAVA    v7w_2390850.jpg  \n",
       "98   FLAVA    v7w_2416322.jpg  \n",
       "\n",
       "[396 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_shap_dfs = []\n",
    "\n",
    "for model_name, filename in zip(model_names, relevant_filenames):\n",
    "\n",
    "    # get the model SHAP dataframe\n",
    "    model_shap_df = pd.read_pickle(os.path.join(shap_map_dir, filename))\n",
    "    # add column with model name\n",
    "    model_shap_df['model'] = model_name\n",
    "    # add to list of dataframes\n",
    "    model_shap_dfs.append(model_shap_df)\n",
    "\n",
    "#combine all dataframes\n",
    "combi_shap_df = pd.concat(model_shap_dfs)\n",
    "combi_shap_df['filename'] = [os.path.basename(path) for path in combi_shap_df['img_path']]\n",
    "combi_shap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add normalized and nonzero SHAP column: setting all negative values to positive and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_shap_maps = []\n",
    "\n",
    "for shap_array in combi_shap_df['model_shap_map']:\n",
    "    \n",
    "    new_shap_array = shap_array.copy()\n",
    "    # new_shap_array[new_shap_array<0] = 0\n",
    "\n",
    "    new_shap_array = np.abs(new_shap_array)\n",
    "\n",
    "\n",
    "    if np.sum(new_shap_array)>0:\n",
    "        new_shap_array = new_shap_array/np.sum(new_shap_array)\n",
    "    new_shap_maps.append(new_shap_array)\n",
    "\n",
    "combi_shap_df['model_shap_positive_normalized'] = new_shap_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_shap_df.to_pickle(\"1_all_xai_maps.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_shap in combi_shap_df['model_shap_positive_normalized']:\n",
    "    if np.sum(new_shap) == 0:\n",
    "        print(\"PROBLEM: THERE IS A TOTALLY EMTPY SHAP MAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    [[0.018459939998592745, 0.02855476230934073, -...\n",
       "5    [[-0.018877267837524414, 0.07358980178833008, ...\n",
       "5    [[0.5498674213886261, 0.6956070959568024, 0.44...\n",
       "5    [[-0.16100779175758362, 0.0764375627040863, -0...\n",
       "Name: model_shap_map, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi_shap_df['model_shap_map'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    [[0.034739605778902866, 0.05373696695722698, 0...\n",
       "5    [[0.006880996059746134, 0.02682438690287738, 0...\n",
       "5    [[0.09857956541765339, 0.12470759778363533, 0....\n",
       "5    [[0.02107458748241377, 0.010005044380554835, 0...\n",
       "Name: model_shap_positive_normalized, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi_shap_df['model_shap_positive_normalized'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
