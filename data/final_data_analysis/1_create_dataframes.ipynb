{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get distance metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'index', 'img_path', 'caption', 'foil',\n",
       "       'linguistic_phenomena', 'model_shap_map', 'n_image_variants', 'model',\n",
       "       'model_shap_positive_normalized', 'human_map',\n",
       "       'shuffled_column_human_map', 'EMD_to_human', 'RC_to_human',\n",
       "       'EMD_to_scrambled_human', 'RC_to_scrambled_human',\n",
       "       'EMD_to_shuffled_column_human', 'RC_to_shuffled_column_human'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_metrics = pd.read_pickle('../comparison_metrics/2_xai_with_distances.pickle')\n",
    "distance_metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get each model's output on each of 99 stimuli into a single dataframe\n",
    "\n",
    "Then filter down to 92 stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "models = [\"LXMERT\", \"CLIP\", \"FLAVA\", \"SigLip\"]\n",
    "\n",
    "#put all models' stimuli output data into a single dataframe\n",
    "stimuli_outputs = [pd.read_pickle(f\"../xai_maps/xai_output/{model_name}_stimuli_output_scores.pickle\") for model_name in models]\n",
    "\n",
    "#add model names column\n",
    "for model_name, model_df in zip(models, stimuli_outputs):\n",
    "    model_df['model']=model_name\n",
    "\n",
    "stimuli_outputs = pd.concat(stimuli_outputs)\n",
    "\n",
    "stimuli_outputs['filename'] = [os.path.basename(path) for path in stimuli_outputs['img_path']]\n",
    "\n",
    "# now filter down to 92 stimuli which have a human distance (because we were able to generate a human map for them!)\n",
    "stimuli_outputs = stimuli_outputs[stimuli_outputs['filename'].isin(list(distance_metrics['filename']))]\n",
    "\n",
    "len(stimuli_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_path', 'caption', 'foil', 'linguistic_phenomena',\n",
       "       'model_pred_caption', 'model_pred_foil', 'model_pred_diff', 'model',\n",
       "       'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli_outputs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all VALSE outputs for each model into a single dataframe\n",
    "\n",
    "This includes ALL outputs including for things that aren't stimuli in our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10548"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"LXMERT\", \"CLIP\", \"FLAVA\", \"SigLip\"]\n",
    "\n",
    "#put all models' stimuli output data into a single dataframe\n",
    "valse_outputs = [pd.read_pickle(f\"../xai_maps/xai_output/{model_name}_all_of_valse_output_scores.pickle\") for model_name in models]\n",
    "\n",
    "#add model names column\n",
    "for model_name, model_df in zip(models, valse_outputs):\n",
    "    model_df['model']=model_name\n",
    "\n",
    "valse_outputs = pd.concat(valse_outputs).reset_index()\n",
    "\n",
    "valse_outputs['filename'] = [os.path.basename(path) for path in valse_outputs['img_path']]\n",
    "\n",
    "len(valse_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model_pred_caption</th>\n",
       "      <th>model_pred_foil</th>\n",
       "      <th>model_pred_diff</th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10547</th>\n",
       "      <td>2636</td>\n",
       "      <td>../../VALSE_data/images/swig/rotting_182.jpg</td>\n",
       "      <td>A hamburger rots the table.</td>\n",
       "      <td>A table rots like a hamburger.</td>\n",
       "      <td>actions</td>\n",
       "      <td>-8.456455</td>\n",
       "      <td>-6.422833</td>\n",
       "      <td>-2.033622</td>\n",
       "      <td>SigLip</td>\n",
       "      <td>rotting_182.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                      img_path  \\\n",
       "10547   2636  ../../VALSE_data/images/swig/rotting_182.jpg   \n",
       "\n",
       "                           caption                            foil  \\\n",
       "10547  A hamburger rots the table.  A table rots like a hamburger.   \n",
       "\n",
       "      linguistic_phenomena  model_pred_caption  model_pred_foil  \\\n",
       "10547              actions           -8.456455        -6.422833   \n",
       "\n",
       "       model_pred_diff   model         filename  \n",
       "10547        -2.033622  SigLip  rotting_182.jpg  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valse_outputs.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create table of distance metrics and model outputs for main 92 sitmuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which columns to keep from each DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model</th>\n",
       "      <th>model_shap_positive_normalized</th>\n",
       "      <th>human_map</th>\n",
       "      <th>RC_to_human</th>\n",
       "      <th>EMD_to_human</th>\n",
       "      <th>model_pred_caption</th>\n",
       "      <th>model_pred_foil</th>\n",
       "      <th>model_pred_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>licking_291.jpg</td>\n",
       "      <td>A cow licks its fur.</td>\n",
       "      <td>A cow wrinkles its fur.</td>\n",
       "      <td>actions</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.07359886674465907, 0.02998819329604594, 0....</td>\n",
       "      <td>[[0.0014743265527438847, 0.01573516504970489, ...</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.983263</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>-0.014034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counting_103.jpg</td>\n",
       "      <td>A person counts money.</td>\n",
       "      <td>A person pays money.</td>\n",
       "      <td>actions</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.10524416414966785, 0.13240805706235903, 0....</td>\n",
       "      <td>[[0.004482754295119378, 0.029023927486055416, ...</td>\n",
       "      <td>-0.464706</td>\n",
       "      <td>1.118272</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v7w_2411632.jpg</td>\n",
       "      <td>There are no people in the photo.</td>\n",
       "      <td>There is at least one person in the photo.</td>\n",
       "      <td>existence</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.005573892832708572, 0.0672021870488928, 0....</td>\n",
       "      <td>[[7.25101021142701e-07, 0.006881846083901585, ...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.516299</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.485952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urinating_251.jpg</td>\n",
       "      <td>A man urinates against a wall.</td>\n",
       "      <td>A man skates against a wall.</td>\n",
       "      <td>actions</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.0298257918219853, 0.13789591026754916, 0.0...</td>\n",
       "      <td>[[0.012884411289709949, 0.0253810418266228, 0....</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.714441</td>\n",
       "      <td>0.602664</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.591192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v7w_2390850.jpg</td>\n",
       "      <td>There are no people in the water.</td>\n",
       "      <td>There is at least one person in the water.</td>\n",
       "      <td>existence</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.034739605778902866, 0.05373696695722698, 0...</td>\n",
       "      <td>[[0.04304823942671234, 0.3141493061042169, 0.2...</td>\n",
       "      <td>0.522446</td>\n",
       "      <td>1.023692</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>v7w_2363335.jpg</td>\n",
       "      <td>There is a mast on the closest boat.</td>\n",
       "      <td>There is no mast on the closest boat.</td>\n",
       "      <td>existence</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>[[0.10762498903891778, 0.10600056876510631, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0038761918414842236,...</td>\n",
       "      <td>-0.265192</td>\n",
       "      <td>1.613585</td>\n",
       "      <td>14.154673</td>\n",
       "      <td>14.714719</td>\n",
       "      <td>-0.560046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>v7w_2367084.jpg</td>\n",
       "      <td>There is a giraffe.</td>\n",
       "      <td>There is no giraffe.</td>\n",
       "      <td>existence</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>[[0.11606520796315897, 0.0032524290430023346, ...</td>\n",
       "      <td>[[0.058031671761254025, 0.011923543607465443, ...</td>\n",
       "      <td>0.382132</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>15.711895</td>\n",
       "      <td>15.363859</td>\n",
       "      <td>0.348036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>v7w_2373121.jpg</td>\n",
       "      <td>There are no clouds in the sky.</td>\n",
       "      <td>There is at least one cloud in the sky.</td>\n",
       "      <td>existence</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>[[0.1333684719184068, 0.02332404943837514, 0.0...</td>\n",
       "      <td>[[0.06944438863843619, 0.3078465814086114, 0.2...</td>\n",
       "      <td>0.185431</td>\n",
       "      <td>1.103381</td>\n",
       "      <td>9.280195</td>\n",
       "      <td>9.946142</td>\n",
       "      <td>-0.665947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>v7w_2390850.jpg</td>\n",
       "      <td>There are no people in the water.</td>\n",
       "      <td>There is at least one person in the water.</td>\n",
       "      <td>existence</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>[[0.010906337368241143, 0.021492206313915848, ...</td>\n",
       "      <td>[[0.04304823942671234, 0.3141493061042169, 0.2...</td>\n",
       "      <td>-0.176139</td>\n",
       "      <td>1.478958</td>\n",
       "      <td>21.434097</td>\n",
       "      <td>17.754848</td>\n",
       "      <td>3.679249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>v7w_2416322.jpg</td>\n",
       "      <td>There is at least one person wearing glasses.</td>\n",
       "      <td>There are no people wearing glasses.</td>\n",
       "      <td>existence</td>\n",
       "      <td>FLAVA</td>\n",
       "      <td>[[0.021852369706205604, 0.027385600377845768, ...</td>\n",
       "      <td>[[0.015623909099073416, 0.022431923603628626, ...</td>\n",
       "      <td>0.531273</td>\n",
       "      <td>0.482080</td>\n",
       "      <td>8.331070</td>\n",
       "      <td>12.362342</td>\n",
       "      <td>-4.031272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                        caption  \\\n",
       "0      licking_291.jpg                           A cow licks its fur.   \n",
       "1     counting_103.jpg                         A person counts money.   \n",
       "2      v7w_2411632.jpg              There are no people in the photo.   \n",
       "3    urinating_251.jpg                 A man urinates against a wall.   \n",
       "4      v7w_2390850.jpg              There are no people in the water.   \n",
       "..                 ...                                            ...   \n",
       "363    v7w_2363335.jpg           There is a mast on the closest boat.   \n",
       "364    v7w_2367084.jpg                            There is a giraffe.   \n",
       "365    v7w_2373121.jpg                There are no clouds in the sky.   \n",
       "366    v7w_2390850.jpg              There are no people in the water.   \n",
       "367    v7w_2416322.jpg  There is at least one person wearing glasses.   \n",
       "\n",
       "                                           foil linguistic_phenomena   model  \\\n",
       "0                       A cow wrinkles its fur.              actions  LXMERT   \n",
       "1                          A person pays money.              actions  LXMERT   \n",
       "2    There is at least one person in the photo.            existence  LXMERT   \n",
       "3                  A man skates against a wall.              actions  LXMERT   \n",
       "4    There is at least one person in the water.            existence  LXMERT   \n",
       "..                                          ...                  ...     ...   \n",
       "363       There is no mast on the closest boat.            existence   FLAVA   \n",
       "364                        There is no giraffe.            existence   FLAVA   \n",
       "365     There is at least one cloud in the sky.            existence   FLAVA   \n",
       "366  There is at least one person in the water.            existence   FLAVA   \n",
       "367        There are no people wearing glasses.            existence   FLAVA   \n",
       "\n",
       "                        model_shap_positive_normalized  \\\n",
       "0    [[0.07359886674465907, 0.02998819329604594, 0....   \n",
       "1    [[0.10524416414966785, 0.13240805706235903, 0....   \n",
       "2    [[0.005573892832708572, 0.0672021870488928, 0....   \n",
       "3    [[0.0298257918219853, 0.13789591026754916, 0.0...   \n",
       "4    [[0.034739605778902866, 0.05373696695722698, 0...   \n",
       "..                                                 ...   \n",
       "363  [[0.10762498903891778, 0.10600056876510631, 0....   \n",
       "364  [[0.11606520796315897, 0.0032524290430023346, ...   \n",
       "365  [[0.1333684719184068, 0.02332404943837514, 0.0...   \n",
       "366  [[0.010906337368241143, 0.021492206313915848, ...   \n",
       "367  [[0.021852369706205604, 0.027385600377845768, ...   \n",
       "\n",
       "                                             human_map  RC_to_human  \\\n",
       "0    [[0.0014743265527438847, 0.01573516504970489, ...    -0.058824   \n",
       "1    [[0.004482754295119378, 0.029023927486055416, ...    -0.464706   \n",
       "2    [[7.25101021142701e-07, 0.006881846083901585, ...     0.300000   \n",
       "3    [[0.012884411289709949, 0.0253810418266228, 0....     0.338235   \n",
       "4    [[0.04304823942671234, 0.3141493061042169, 0.2...     0.522446   \n",
       "..                                                 ...          ...   \n",
       "363  [[0.0, 0.0, 0.0, 0.0], [0.0038761918414842236,...    -0.265192   \n",
       "364  [[0.058031671761254025, 0.011923543607465443, ...     0.382132   \n",
       "365  [[0.06944438863843619, 0.3078465814086114, 0.2...     0.185431   \n",
       "366  [[0.04304823942671234, 0.3141493061042169, 0.2...    -0.176139   \n",
       "367  [[0.015623909099073416, 0.022431923603628626, ...     0.531273   \n",
       "\n",
       "     EMD_to_human  model_pred_caption  model_pred_foil  model_pred_diff  \n",
       "0        0.983263            0.004516         0.018551        -0.014034  \n",
       "1        1.118272            0.001854         0.001183         0.000671  \n",
       "2        0.897321            0.516299         0.030346         0.485952  \n",
       "3        0.714441            0.602664         0.011472         0.591192  \n",
       "4        1.023692            0.011590         0.001473         0.010117  \n",
       "..            ...                 ...              ...              ...  \n",
       "363      1.613585           14.154673        14.714719        -0.560046  \n",
       "364      0.811894           15.711895        15.363859         0.348036  \n",
       "365      1.103381            9.280195         9.946142        -0.665947  \n",
       "366      1.478958           21.434097        17.754848         3.679249  \n",
       "367      0.482080            8.331070        12.362342        -4.031272  \n",
       "\n",
       "[368 rows x 12 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_metrics_filtered = distance_metrics[['filename', 'caption', 'foil', 'linguistic_phenomena', 'model', 'model_shap_positive_normalized', 'human_map', 'RC_to_human','EMD_to_human']]\n",
    "stimuli_outputs_filtered = stimuli_outputs[['filename', 'model', 'model_pred_caption', 'model_pred_foil', 'model_pred_diff']]\n",
    "\n",
    "merged_df = pd.merge(distance_metrics_filtered, stimuli_outputs_filtered, on=['filename','model'])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that it worked with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model</th>\n",
       "      <th>model_shap_positive_normalized</th>\n",
       "      <th>human_map</th>\n",
       "      <th>RC_to_human</th>\n",
       "      <th>EMD_to_human</th>\n",
       "      <th>model_pred_caption</th>\n",
       "      <th>model_pred_foil</th>\n",
       "      <th>model_pred_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counting_103.jpg</td>\n",
       "      <td>A person counts money.</td>\n",
       "      <td>A person pays money.</td>\n",
       "      <td>actions</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.10524416414966785, 0.13240805706235903, 0....</td>\n",
       "      <td>[[0.004482754295119378, 0.029023927486055416, ...</td>\n",
       "      <td>-0.464706</td>\n",
       "      <td>1.118272</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                 caption                  foil  \\\n",
       "1  counting_103.jpg  A person counts money.  A person pays money.   \n",
       "\n",
       "  linguistic_phenomena   model  \\\n",
       "1              actions  LXMERT   \n",
       "\n",
       "                      model_shap_positive_normalized  \\\n",
       "1  [[0.10524416414966785, 0.13240805706235903, 0....   \n",
       "\n",
       "                                           human_map  RC_to_human  \\\n",
       "1  [[0.004482754295119378, 0.029023927486055416, ...    -0.464706   \n",
       "\n",
       "   EMD_to_human  model_pred_caption  model_pred_foil  model_pred_diff  \n",
       "1      1.118272            0.001854         0.001183         0.000671  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['filename']=='counting_103.jpg'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>index</th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model_shap_map</th>\n",
       "      <th>n_image_variants</th>\n",
       "      <th>model</th>\n",
       "      <th>model_shap_positive_normalized</th>\n",
       "      <th>human_map</th>\n",
       "      <th>shuffled_column_human_map</th>\n",
       "      <th>EMD_to_human</th>\n",
       "      <th>RC_to_human</th>\n",
       "      <th>EMD_to_scrambled_human</th>\n",
       "      <th>RC_to_scrambled_human</th>\n",
       "      <th>EMD_to_shuffled_column_human</th>\n",
       "      <th>RC_to_shuffled_column_human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>counting_103.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>../../VALSE_data/images/swig/counting_103.jpg</td>\n",
       "      <td>A person counts money.</td>\n",
       "      <td>A person pays money.</td>\n",
       "      <td>actions</td>\n",
       "      <td>[[-0.0010253147265757434, 0.001289952102524694...</td>\n",
       "      <td>172</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>[[0.10524416414966785, 0.13240805706235903, 0....</td>\n",
       "      <td>[[0.004482754295119378, 0.029023927486055416, ...</td>\n",
       "      <td>[[0.058031671761254025, 0.011923543607465443, ...</td>\n",
       "      <td>1.118272</td>\n",
       "      <td>-0.464706</td>\n",
       "      <td>0.750563</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>1.144368</td>\n",
       "      <td>0.238833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  index                                       img_path  \\\n",
       "2  counting_103.jpg      2  ../../VALSE_data/images/swig/counting_103.jpg   \n",
       "\n",
       "                  caption                  foil linguistic_phenomena  \\\n",
       "2  A person counts money.  A person pays money.              actions   \n",
       "\n",
       "                                      model_shap_map  n_image_variants  \\\n",
       "2  [[-0.0010253147265757434, 0.001289952102524694...               172   \n",
       "\n",
       "    model                     model_shap_positive_normalized  \\\n",
       "2  LXMERT  [[0.10524416414966785, 0.13240805706235903, 0....   \n",
       "\n",
       "                                           human_map  \\\n",
       "2  [[0.004482754295119378, 0.029023927486055416, ...   \n",
       "\n",
       "                           shuffled_column_human_map  EMD_to_human  \\\n",
       "2  [[0.058031671761254025, 0.011923543607465443, ...      1.118272   \n",
       "\n",
       "   RC_to_human  EMD_to_scrambled_human  RC_to_scrambled_human  \\\n",
       "2    -0.464706                0.750563               0.170588   \n",
       "\n",
       "   EMD_to_shuffled_column_human  RC_to_shuffled_column_human  \n",
       "2                      1.144368                     0.238833  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_metrics[distance_metrics['filename']=='counting_103.jpg'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model_pred_caption</th>\n",
       "      <th>model_pred_foil</th>\n",
       "      <th>model_pred_diff</th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>../../VALSE_data/images/swig/counting_103.jpg</td>\n",
       "      <td>A person counts money.</td>\n",
       "      <td>A person pays money.</td>\n",
       "      <td>actions</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>counting_103.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         img_path                 caption  \\\n",
       "20  ../../VALSE_data/images/swig/counting_103.jpg  A person counts money.   \n",
       "\n",
       "                    foil linguistic_phenomena  model_pred_caption  \\\n",
       "20  A person pays money.              actions            0.001854   \n",
       "\n",
       "    model_pred_foil  model_pred_diff   model          filename  \n",
       "20         0.001183         0.000671  LXMERT  counting_103.jpg  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli_outputs[stimuli_outputs['filename']=='counting_103.jpg'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_pickle(\"distances_outputs_table.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get VALSE summary stats for RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>model_pred_caption</th>\n",
       "      <th>model_pred_foil</th>\n",
       "      <th>model_pred_diff</th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../../VALSE_data/images/coco2017/000000462576.jpg</td>\n",
       "      <td>Breakfast items including juice are on the table.</td>\n",
       "      <td>Breakfast items including juice are off the ta...</td>\n",
       "      <td>relations</td>\n",
       "      <td>0.056552</td>\n",
       "      <td>0.087249</td>\n",
       "      <td>-0.030697</td>\n",
       "      <td>LXMERT</td>\n",
       "      <td>000000462576.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           img_path  \\\n",
       "0      0  ../../VALSE_data/images/coco2017/000000462576.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  Breakfast items including juice are on the table.   \n",
       "\n",
       "                                                foil linguistic_phenomena  \\\n",
       "0  Breakfast items including juice are off the ta...            relations   \n",
       "\n",
       "   model_pred_caption  model_pred_foil  model_pred_diff   model  \\\n",
       "0            0.056552         0.087249        -0.030697  LXMERT   \n",
       "\n",
       "           filename  \n",
       "0  000000462576.jpg  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valse_outputs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "model_stats_valse = defaultdict(list)\n",
    "model_stats_valse['metric (VALSE wide model output)'] = ['mean','std','acc_overall','acc_existence','acc_relations','acc_actions']\n",
    "\n",
    "for model in models:\n",
    "    filtered_df = valse_outputs[valse_outputs['model']==model]\n",
    "\n",
    "    # calculate mean and std of output for each model\n",
    "    mean = np.mean(list(filtered_df['model_pred_diff']))\n",
    "    std = np.std(list(filtered_df['model_pred_diff']))\n",
    "\n",
    "    model_stats_valse[model].append(mean)\n",
    "    model_stats_valse[model].append(std)\n",
    "\n",
    "    # calculate overall accuracy of model --positive outputs over total outputs\n",
    "    accuracy = len(filtered_df[filtered_df['model_pred_diff']>=0])/len(filtered_df)\n",
    "    model_stats_valse[model].append(accuracy)\n",
    "\n",
    "    # calculate accuracy for each phenomenon separately \n",
    "    for phenomenon in ['existence','relations','actions']:\n",
    "\n",
    "        # filter to phenomenon\n",
    "        sub_filtered_df = filtered_df[filtered_df['linguistic_phenomena']==phenomenon]\n",
    "\n",
    "        # accuracy is positive outputs over total outputs\n",
    "        accuracy = len(sub_filtered_df[sub_filtered_df['model_pred_diff']>=0])/len(sub_filtered_df)\n",
    "        model_stats_valse[model].append(accuracy)\n",
    "\n",
    "valse_stats_df = pd.DataFrame(model_stats_valse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "valse_stats_df.to_pickle(\"valse_statistics.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric (VALSE wide model output)</th>\n",
       "      <th>LXMERT</th>\n",
       "      <th>CLIP</th>\n",
       "      <th>FLAVA</th>\n",
       "      <th>SigLip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.953458</td>\n",
       "      <td>1.300020</td>\n",
       "      <td>1.024050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>0.164757</td>\n",
       "      <td>1.709227</td>\n",
       "      <td>2.900839</td>\n",
       "      <td>2.333226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_overall</td>\n",
       "      <td>0.532802</td>\n",
       "      <td>0.715965</td>\n",
       "      <td>0.672355</td>\n",
       "      <td>0.667804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_existence</td>\n",
       "      <td>0.768317</td>\n",
       "      <td>0.691089</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.695050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_relations</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.659813</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.605607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_actions</td>\n",
       "      <td>0.433939</td>\n",
       "      <td>0.742642</td>\n",
       "      <td>0.702567</td>\n",
       "      <td>0.680025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric (VALSE wide model output)    LXMERT      CLIP     FLAVA    SigLip\n",
       "0                             mean  0.010805  0.953458  1.300020  1.024050\n",
       "1                              std  0.164757  1.709227  2.900839  2.333226\n",
       "2                      acc_overall  0.532802  0.715965  0.672355  0.667804\n",
       "3                    acc_existence  0.768317  0.691089  0.623762  0.695050\n",
       "4                    acc_relations  0.605607  0.659813  0.628037  0.605607\n",
       "5                      acc_actions  0.433939  0.742642  0.702567  0.680025"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valse_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
