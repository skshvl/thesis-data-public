{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is NOT used in the mian analysis. It is an artefact of an earlier stage before STIMULI4 was collected. It is kept because it was used in determining which stimuli to send in STIMULI4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>mask</th>\n",
       "      <th>points_clicked</th>\n",
       "      <th>filename</th>\n",
       "      <th>answer</th>\n",
       "      <th>time_to_submit</th>\n",
       "      <th>prolific_session_id</th>\n",
       "      <th>nr_clicks</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>Approval</th>\n",
       "      <th>clip_pred_diff</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>000000005529.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>17.695961</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>0</td>\n",
       "      <td>A person on skis is skiing down a snowy hill.</td>\n",
       "      <td>A person on skis is skiing up a snowy hill.</td>\n",
       "      <td>relations</td>\n",
       "      <td>Approve</td>\n",
       "      <td>0.083982</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000005529.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(200.39996337890625, 126.19999694824219)]</td>\n",
       "      <td>000000033368.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>15.218655</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>1</td>\n",
       "      <td>A tennis player is standing on the court.</td>\n",
       "      <td>A tennis player is standing off the court.</td>\n",
       "      <td>relations</td>\n",
       "      <td>Approve</td>\n",
       "      <td>2.950064</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000033368.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            instance_id                                               mask  \\\n",
       "0  20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "1  20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "\n",
       "                               points_clicked          filename   answer  \\\n",
       "0                                          []  000000005529.jpg  caption   \n",
       "1  [(200.39996337890625, 126.19999694824219)]  000000033368.jpg  caption   \n",
       "\n",
       "   time_to_submit       prolific_session_id  nr_clicks  \\\n",
       "0       17.695961  65bd0acc6b7a578310acc40b          0   \n",
       "1       15.218655  65bd0acc6b7a578310acc40b          1   \n",
       "\n",
       "                                         caption  \\\n",
       "0  A person on skis is skiing down a snowy hill.   \n",
       "1      A tennis player is standing on the court.   \n",
       "\n",
       "                                          foil linguistic_phenomena Approval  \\\n",
       "0  A person on skis is skiing up a snowy hill.            relations  Approve   \n",
       "1   A tennis player is standing off the court.            relations  Approve   \n",
       "\n",
       "   clip_pred_diff                                        img_path  \n",
       "0        0.083982  ../VALSE_data/images/coco2017/000000005529.jpg  \n",
       "1        2.950064  ../VALSE_data/images/coco2017/000000033368.jpg  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_pickle(\"1_merged_prolific_data_minus_stim4.pickle\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also create a version without the training stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_train_stim = df[df['filename'] != 'v7w_2391321.jpg']\n",
    "len(df_without_train_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_without_train_stim.filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on the user submissions (EXCLUDING the training stimulus)\n",
    "\n",
    "KEEP IN MIND that the \"training\" cow image is vastly overrepresented\n",
    "\n",
    "1. Filter to only the rows with clicked points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = df_without_train_stim[df_without_train_stim['points_clicked'].astype(bool)]\n",
    "len(filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filter those to only rows with answer == caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = filter_df[filter_df['answer']==\"caption\"]\n",
    "len(filter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(filter_df.filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run stats on this to see how many are left for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following lists how many filenames have each count of submissions that are correct and have points clicked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    32\n",
       "3    29\n",
       "2    17\n",
       "5    17\n",
       "1     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_counts = filter_df.groupby(['filename']).size()\n",
    "print(\"The following lists how many filenames have each count of submissions that are correct and have points clicked\")\n",
    "filename_counts.value_counts() # this sums to 98 but that is because one file evidently has NO cases where correct caption + clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_df.groupby(['filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000000389684.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one file is MISSING -- which one?\n",
    "\n",
    "for filename in set(df_without_train_stim.filename):\n",
    "    if filename not in set(filter_df.filename):\n",
    "        missing = filename\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>mask</th>\n",
       "      <th>points_clicked</th>\n",
       "      <th>filename</th>\n",
       "      <th>answer</th>\n",
       "      <th>time_to_submit</th>\n",
       "      <th>prolific_session_id</th>\n",
       "      <th>nr_clicks</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>Approval</th>\n",
       "      <th>clip_pred_diff</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>000000389684.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>27.823650</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>0</td>\n",
       "      <td>a man walks down a sidewalk as a vehicle passes</td>\n",
       "      <td>A man walks up a sidewalk as a vehicle passes</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000389684.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>20240202153133853542</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>000000389684.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>18.005927</td>\n",
       "      <td>65bd0acd2c3df3a5127f29b9</td>\n",
       "      <td>0</td>\n",
       "      <td>a man walks down a sidewalk as a vehicle passes</td>\n",
       "      <td>A man walks up a sidewalk as a vehicle passes</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000389684.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20240201125402294500</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>000000389684.jpg</td>\n",
       "      <td>Cannot answer</td>\n",
       "      <td>4.337953</td>\n",
       "      <td>65bb945f8c0f55f083ec04ce</td>\n",
       "      <td>0</td>\n",
       "      <td>a man walks down a sidewalk as a vehicle passes</td>\n",
       "      <td>A man walks up a sidewalk as a vehicle passes</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000389684.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>20240201125949942734</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(167.5, 235), (173.5, 244), (172.5, 230), (50...</td>\n",
       "      <td>000000389684.jpg</td>\n",
       "      <td>foil</td>\n",
       "      <td>43.988519</td>\n",
       "      <td>65bb956eea9ea39b17c1cee2</td>\n",
       "      <td>4</td>\n",
       "      <td>a man walks down a sidewalk as a vehicle passes</td>\n",
       "      <td>A man walks up a sidewalk as a vehicle passes</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000389684.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>20240203083058032730</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(174, 251), (188, 258)]</td>\n",
       "      <td>000000389684.jpg</td>\n",
       "      <td>foil</td>\n",
       "      <td>22.764719</td>\n",
       "      <td>65bdf9bb8c2782e981fe9320</td>\n",
       "      <td>2</td>\n",
       "      <td>a man walks down a sidewalk as a vehicle passes</td>\n",
       "      <td>A man walks up a sidewalk as a vehicle passes</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000389684.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              instance_id                                               mask  \\\n",
       "6    20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "210  20240202153133853542  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "278  20240201125402294500  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "312  20240201125949942734  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "414  20240203083058032730  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "\n",
       "                                        points_clicked          filename  \\\n",
       "6                                                   []  000000389684.jpg   \n",
       "210                                                 []  000000389684.jpg   \n",
       "278                                                 []  000000389684.jpg   \n",
       "312  [(167.5, 235), (173.5, 244), (172.5, 230), (50...  000000389684.jpg   \n",
       "414                           [(174, 251), (188, 258)]  000000389684.jpg   \n",
       "\n",
       "            answer  time_to_submit       prolific_session_id  nr_clicks  \\\n",
       "6          caption       27.823650  65bd0acc6b7a578310acc40b          0   \n",
       "210        caption       18.005927  65bd0acd2c3df3a5127f29b9          0   \n",
       "278  Cannot answer        4.337953  65bb945f8c0f55f083ec04ce          0   \n",
       "312           foil       43.988519  65bb956eea9ea39b17c1cee2          4   \n",
       "414           foil       22.764719  65bdf9bb8c2782e981fe9320          2   \n",
       "\n",
       "                                             caption  \\\n",
       "6    a man walks down a sidewalk as a vehicle passes   \n",
       "210  a man walks down a sidewalk as a vehicle passes   \n",
       "278  a man walks down a sidewalk as a vehicle passes   \n",
       "312  a man walks down a sidewalk as a vehicle passes   \n",
       "414  a man walks down a sidewalk as a vehicle passes   \n",
       "\n",
       "                                              foil linguistic_phenomena  \\\n",
       "6    A man walks up a sidewalk as a vehicle passes            relations   \n",
       "210  A man walks up a sidewalk as a vehicle passes            relations   \n",
       "278  A man walks up a sidewalk as a vehicle passes            relations   \n",
       "312  A man walks up a sidewalk as a vehicle passes            relations   \n",
       "414  A man walks up a sidewalk as a vehicle passes            relations   \n",
       "\n",
       "    Approval  clip_pred_diff                                        img_path  \n",
       "6     Unsure       -0.291231  ../VALSE_data/images/coco2017/000000389684.jpg  \n",
       "210   Unsure       -0.291231  ../VALSE_data/images/coco2017/000000389684.jpg  \n",
       "278   Unsure       -0.291231  ../VALSE_data/images/coco2017/000000389684.jpg  \n",
       "312   Unsure       -0.291231  ../VALSE_data/images/coco2017/000000389684.jpg  \n",
       "414   Unsure       -0.291231  ../VALSE_data/images/coco2017/000000389684.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filename']==missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate list of filenames which: have 3+ correct answers with points clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering the dataframe we found that 78 out of 99 stimuli had at least 3/5 answers that were both correct and contained points\n"
     ]
    }
   ],
   "source": [
    "filtered_filenames = filename_counts[filename_counts >= 3].index\n",
    "print(f\"After filtering the dataframe we found that {len(filtered_filenames)} out of 99 stimuli had at least 3/5 answers that were both correct and contained points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Generate dataframe containing only filenames who have 3+ correct answers with points clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>mask</th>\n",
       "      <th>points_clicked</th>\n",
       "      <th>filename</th>\n",
       "      <th>answer</th>\n",
       "      <th>time_to_submit</th>\n",
       "      <th>prolific_session_id</th>\n",
       "      <th>nr_clicks</th>\n",
       "      <th>caption</th>\n",
       "      <th>foil</th>\n",
       "      <th>linguistic_phenomena</th>\n",
       "      <th>Approval</th>\n",
       "      <th>clip_pred_diff</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(200.39996337890625, 126.19999694824219)]</td>\n",
       "      <td>000000033368.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>15.218655</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>1</td>\n",
       "      <td>A tennis player is standing on the court.</td>\n",
       "      <td>A tennis player is standing off the court.</td>\n",
       "      <td>relations</td>\n",
       "      <td>Approve</td>\n",
       "      <td>2.950064</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000033368.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(202.39996337890625, 332.1999969482422), (203...</td>\n",
       "      <td>000000478393.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>18.931784</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>2</td>\n",
       "      <td>Teddybear, kitten and calico cat are all takin...</td>\n",
       "      <td>Teddybear, kitten and calico cat are all takin...</td>\n",
       "      <td>relations</td>\n",
       "      <td>Approve</td>\n",
       "      <td>0.345295</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000478393.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(276.39996337890625, 311.1999969482422), (264...</td>\n",
       "      <td>000000488385.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>18.913057</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>3</td>\n",
       "      <td>A black and white motorcycle parked on the sid...</td>\n",
       "      <td>A black and white motorcycle parked on the sid...</td>\n",
       "      <td>relations</td>\n",
       "      <td>Unsure</td>\n",
       "      <td>-0.496513</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000488385.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(256.39996337890625, 352.1999969482422)]</td>\n",
       "      <td>000000493019.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>17.844551</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>1</td>\n",
       "      <td>A group of zebras are bending down and eating ...</td>\n",
       "      <td>A group of zebras are bending up and eating a ...</td>\n",
       "      <td>relations</td>\n",
       "      <td>Approve</td>\n",
       "      <td>0.787514</td>\n",
       "      <td>../VALSE_data/images/coco2017/000000493019.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20240202153131339291</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(164.39996337890625, 364.1999969482422)]</td>\n",
       "      <td>caressing_51.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>8.999819</td>\n",
       "      <td>65bd0acc6b7a578310acc40b</td>\n",
       "      <td>1</td>\n",
       "      <td>A man caresses a man.</td>\n",
       "      <td>A man chases a man.</td>\n",
       "      <td>actions</td>\n",
       "      <td>Approve</td>\n",
       "      <td>3.222179</td>\n",
       "      <td>../VALSE_data/images/swig/caressing_51.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>20240204143913560556</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(120, 198), (265, 190), (273, 185)]</td>\n",
       "      <td>v7w_2361437.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>32.974377</td>\n",
       "      <td>65bf9f4014e422cb67a1ad0e</td>\n",
       "      <td>3</td>\n",
       "      <td>There is at least one cow shown.</td>\n",
       "      <td>There are no cows shown.</td>\n",
       "      <td>existence</td>\n",
       "      <td>Approve</td>\n",
       "      <td>1.581106</td>\n",
       "      <td>../VALSE_data/images/v7w/v7w_2361437.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>20240204143913560556</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(124, 307), (54, 99), (69, 174)]</td>\n",
       "      <td>v7w_2367084.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>23.476451</td>\n",
       "      <td>65bf9f4014e422cb67a1ad0e</td>\n",
       "      <td>3</td>\n",
       "      <td>There is a giraffe.</td>\n",
       "      <td>There is no giraffe.</td>\n",
       "      <td>existence</td>\n",
       "      <td>Approve</td>\n",
       "      <td>1.729998</td>\n",
       "      <td>../VALSE_data/images/v7w/v7w_2367084.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>20240204143913560556</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(206, 268), (91, 95), (317, 92), (201, 83), (...</td>\n",
       "      <td>v7w_2373121.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>47.739632</td>\n",
       "      <td>65bf9f4014e422cb67a1ad0e</td>\n",
       "      <td>7</td>\n",
       "      <td>There are no clouds in the sky.</td>\n",
       "      <td>There is at least one cloud in the sky.</td>\n",
       "      <td>existence</td>\n",
       "      <td>Approve</td>\n",
       "      <td>0.784605</td>\n",
       "      <td>../VALSE_data/images/v7w/v7w_2373121.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>20240204143913560556</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(178, 83), (160, 95), (252, 102), (322, 71), ...</td>\n",
       "      <td>v7w_2390850.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>91.203454</td>\n",
       "      <td>65bf9f4014e422cb67a1ad0e</td>\n",
       "      <td>7</td>\n",
       "      <td>There are no people in the water.</td>\n",
       "      <td>There is at least one person in the water.</td>\n",
       "      <td>existence</td>\n",
       "      <td>Approve</td>\n",
       "      <td>0.839369</td>\n",
       "      <td>../VALSE_data/images/v7w/v7w_2390850.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>20240204143913560556</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[(103, 162), (107, 211), (117, 229)]</td>\n",
       "      <td>v7w_2416322.jpg</td>\n",
       "      <td>caption</td>\n",
       "      <td>23.704125</td>\n",
       "      <td>65bf9f4014e422cb67a1ad0e</td>\n",
       "      <td>3</td>\n",
       "      <td>There is at least one person wearing glasses.</td>\n",
       "      <td>There are no people wearing glasses.</td>\n",
       "      <td>existence</td>\n",
       "      <td>Approve</td>\n",
       "      <td>1.025522</td>\n",
       "      <td>../VALSE_data/images/v7w/v7w_2416322.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              instance_id                                               mask  \\\n",
       "1    20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "8    20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "9    20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "10   20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "11   20240202153131339291  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "..                    ...                                                ...   \n",
       "503  20240204143913560556  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "505  20240204143913560556  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "506  20240204143913560556  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "507  20240204143913560556  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "509  20240204143913560556  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "\n",
       "                                        points_clicked          filename  \\\n",
       "1           [(200.39996337890625, 126.19999694824219)]  000000033368.jpg   \n",
       "8    [(202.39996337890625, 332.1999969482422), (203...  000000478393.jpg   \n",
       "9    [(276.39996337890625, 311.1999969482422), (264...  000000488385.jpg   \n",
       "10           [(256.39996337890625, 352.1999969482422)]  000000493019.jpg   \n",
       "11           [(164.39996337890625, 364.1999969482422)]  caressing_51.jpg   \n",
       "..                                                 ...               ...   \n",
       "503               [(120, 198), (265, 190), (273, 185)]   v7w_2361437.jpg   \n",
       "505                  [(124, 307), (54, 99), (69, 174)]   v7w_2367084.jpg   \n",
       "506  [(206, 268), (91, 95), (317, 92), (201, 83), (...   v7w_2373121.jpg   \n",
       "507  [(178, 83), (160, 95), (252, 102), (322, 71), ...   v7w_2390850.jpg   \n",
       "509               [(103, 162), (107, 211), (117, 229)]   v7w_2416322.jpg   \n",
       "\n",
       "      answer  time_to_submit       prolific_session_id  nr_clicks  \\\n",
       "1    caption       15.218655  65bd0acc6b7a578310acc40b          1   \n",
       "8    caption       18.931784  65bd0acc6b7a578310acc40b          2   \n",
       "9    caption       18.913057  65bd0acc6b7a578310acc40b          3   \n",
       "10   caption       17.844551  65bd0acc6b7a578310acc40b          1   \n",
       "11   caption        8.999819  65bd0acc6b7a578310acc40b          1   \n",
       "..       ...             ...                       ...        ...   \n",
       "503  caption       32.974377  65bf9f4014e422cb67a1ad0e          3   \n",
       "505  caption       23.476451  65bf9f4014e422cb67a1ad0e          3   \n",
       "506  caption       47.739632  65bf9f4014e422cb67a1ad0e          7   \n",
       "507  caption       91.203454  65bf9f4014e422cb67a1ad0e          7   \n",
       "509  caption       23.704125  65bf9f4014e422cb67a1ad0e          3   \n",
       "\n",
       "                                               caption  \\\n",
       "1            A tennis player is standing on the court.   \n",
       "8    Teddybear, kitten and calico cat are all takin...   \n",
       "9    A black and white motorcycle parked on the sid...   \n",
       "10   A group of zebras are bending down and eating ...   \n",
       "11                               A man caresses a man.   \n",
       "..                                                 ...   \n",
       "503                   There is at least one cow shown.   \n",
       "505                                There is a giraffe.   \n",
       "506                    There are no clouds in the sky.   \n",
       "507                  There are no people in the water.   \n",
       "509      There is at least one person wearing glasses.   \n",
       "\n",
       "                                                  foil linguistic_phenomena  \\\n",
       "1           A tennis player is standing off the court.            relations   \n",
       "8    Teddybear, kitten and calico cat are all takin...            relations   \n",
       "9    A black and white motorcycle parked on the sid...            relations   \n",
       "10   A group of zebras are bending up and eating a ...            relations   \n",
       "11                                 A man chases a man.              actions   \n",
       "..                                                 ...                  ...   \n",
       "503                           There are no cows shown.            existence   \n",
       "505                               There is no giraffe.            existence   \n",
       "506            There is at least one cloud in the sky.            existence   \n",
       "507         There is at least one person in the water.            existence   \n",
       "509               There are no people wearing glasses.            existence   \n",
       "\n",
       "    Approval  clip_pred_diff                                        img_path  \n",
       "1    Approve        2.950064  ../VALSE_data/images/coco2017/000000033368.jpg  \n",
       "8    Approve        0.345295  ../VALSE_data/images/coco2017/000000478393.jpg  \n",
       "9     Unsure       -0.496513  ../VALSE_data/images/coco2017/000000488385.jpg  \n",
       "10   Approve        0.787514  ../VALSE_data/images/coco2017/000000493019.jpg  \n",
       "11   Approve        3.222179      ../VALSE_data/images/swig/caressing_51.jpg  \n",
       "..       ...             ...                                             ...  \n",
       "503  Approve        1.581106        ../VALSE_data/images/v7w/v7w_2361437.jpg  \n",
       "505  Approve        1.729998        ../VALSE_data/images/v7w/v7w_2367084.jpg  \n",
       "506  Approve        0.784605        ../VALSE_data/images/v7w/v7w_2373121.jpg  \n",
       "507  Approve        0.839369        ../VALSE_data/images/v7w/v7w_2390850.jpg  \n",
       "509  Approve        1.025522        ../VALSE_data/images/v7w/v7w_2416322.jpg  \n",
       "\n",
       "[300 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = filter_df[filter_df['filename'].isin(filtered_filenames)]\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'answer' in the final dataframe:/n answer\n",
      "caption    300\n",
      "Name: count, dtype: int64\n",
      "Minimum number of points clicked in final dataframe: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Value counts for 'answer' in the final dataframe:/n\", filter_df.answer.value_counts())\n",
    "print(\"Minimum number of points clicked in final dataframe:\", min(len(points) for points in filter_df['points_clicked']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export final dataframe - submissions to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df.to_pickle(\"2_merged_prolific_data_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALERT: We need to get more data. Use the analysis above to identify which stimuli have only 2 validated interactions. Produce a list of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below should output a list of 17 files. If another number, something is wrong. We have in the original 3 stimuli waves 17 stimuli which have 2 valid interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_filenames = filename_counts[filename_counts == 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desired_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000000057027.jpg', '000000089880.jpg', '000000121506.jpg',\n",
       "       '000000121586.jpg', '000000164885.jpg', '000000376307.jpg',\n",
       "       '000000378673.jpg', '000000393093.jpg', '000000411953.jpg',\n",
       "       'admiring_372.jpg', 'buttoning_129.jpg', 'counting_103.jpg',\n",
       "       'peeing_115.jpg', 'punting_194.jpg', 'socializing_108.jpg',\n",
       "       'tripping_125.jpg', 'v7w_2363335.jpg'],\n",
       "      dtype='object', name='filename')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now generate stimuli 4 with the files above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
